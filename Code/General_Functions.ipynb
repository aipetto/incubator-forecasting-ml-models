{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cc30440f-b5a3-425c-8399-bbb99ba30b26",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Notebook with all the general purpose functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a79057a4-4642-4d96-bec8-75139ea5213d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This notebook contains the general purpose functions that will be used throughout the solution. In this context,\n",
    "\"general purpose\" means that these functions dont belong to a particular process such as preprocessing, modeling or\n",
    "prediction; however, they are used as auxiliary functions to accomplish specific tasks within the code while preserving\n",
    "modularity and order.\n",
    "\n",
    "The functions included are:\n",
    "\n",
    "| Function | Description |\n",
    "| -------- | ----------- |\n",
    "| `split_series`  | splits a time series into train and test sets according to the given dates |\n",
    "| `add_holidays`  | adds the holidays to the time series dataset as an additional binary column |\n",
    "| `shift_time_series` | creates a set of lags and leads of a specific column |\n",
    "| `create_orders_lags` | creates a set of lags of a time series |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6539ef45-e68e-4120-9a21-bcd287b8e5d1",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###### Definition of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cf50a953-d7d9-45ba-8938-a35a9f68270e",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_series(data, start_test, end_test):\n",
    "    \"\"\"\n",
    "    Splits a time series into train and test sets according to the given date boundaries.\n",
    "\n",
    "    Note that all records before the start of the test set are considered to be part of the train set. Furthermore, the\n",
    "    end of the train set and start of the test set are assumed to be contiguous.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "        data (pd.DataFrame): Dataset with the time series to split.\n",
    "        start_test (str): Start of test set (included).\n",
    "        end_test (str): End of test set (included).\n",
    "\n",
    "    Returns\n",
    "    ________\n",
    "        train_df (pd.DataFrame): Train set DataFrame.\n",
    "        test_df (pd.DataFrame): Test set DataFrame.\n",
    "    \"\"\"\n",
    "    # Splitting dataset\n",
    "    train_df = data[data['ds'] < pd.to_datetime(start_test)]\n",
    "    test_df = data[(data['ds'] >= pd.to_datetime(start_test)) & (data['ds'] <= pd.to_datetime(end_test))]\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9e7fd5e8-d1c5-4bbd-9648-6d8d01d12878",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_holidays(df_data, df_holidays):\n",
    "    \"\"\"\n",
    "    Adds the holidays to the time series dataset as an additional binary column, where the value of this column is 1 for\n",
    "    the dates where there is a holiday and 0 otherwise.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "        df_data (pd.DataFrame): Dataset with the time series\n",
    "        df_holidays (pd.DataFrame): Dataset with holidays.\n",
    "\n",
    "    Returns\n",
    "    ________\n",
    "        df_data (pd.DataFrame): Same input \"df_data\" dataset but modified after adding the binary column with the\n",
    "            holidays.\n",
    "    \"\"\"\n",
    "    # Adding holidays column to the dataset\n",
    "    df_data[\"holiday\"] = 0\n",
    "\n",
    "    # Identifying dates with holidays\n",
    "    rows = pd.merge(df_data, df_holidays, on=\"ds\", how=\"left\", indicator=True)[\"_merge\"] == \"both\"\n",
    "\n",
    "    # Replacing holidays with 1\n",
    "    df_data.loc[rows, \"holiday\"] = 1\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def shift_time_series(sdf_data, column, lag_lead=7, suf=\"\"):\n",
    "    \"\"\"\n",
    "    Creates a set of lags and leads of the column specified in \"column\". The number of lags and leads is the same and is\n",
    "    defined by the \"lag_lead\" argument.\n",
    "\n",
    "    Note that this function operates over Spark Dataframes only.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "        sdf_data (pyspark.sql.DataFrame): Dataset with the column to shift\n",
    "        column (str): Name of the column to shift.\n",
    "        lag_lead (int): Number of lags and leads to create from \"column\".\n",
    "        suf (str, defaults to \"\"): Suffix to use for the new columns.\n",
    "\n",
    "    Returns\n",
    "    ________\n",
    "        sdf_data (pyspark.sql.DataFrame): Same input dataset but modified after adding the columns of lags and leads.\n",
    "    \"\"\"\n",
    "    # Defining granularity level of the window\n",
    "    window = (\n",
    "        Window.partitionBy([\"n_sku\"])\n",
    "        .orderBy([\"ds\"])\n",
    "    )\n",
    "\n",
    "    # Creating leads and lags\n",
    "    for shift in range(lag_lead):\n",
    "        sdf_data = sdf_data.withColumn(\"lag_{}\".format(shift + 1) + suf, lag(sdf_data[column], offset = shift + 1).over(window)) \\\n",
    "            .withColumn(\"lead_{}\".format(shift + 1) + suf, lag(sdf_data[column], offset = -1 * (shift + 1)).over(window))\n",
    "\n",
    "    return sdf_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_orders_lags(df, column, lags=7):\n",
    "    \"\"\"\n",
    "    Creates a set of lags of a column that contains a time series. The number of lags is defined by the \"lags\" argument.\n",
    "\n",
    "    Note that this function operates over Pandas Dataframes only.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "        df (pd.DataFrame): Dataframe with column \"y\" that will be used to create lags\n",
    "        column (str): Name of the column to shift.\n",
    "        lags (int, defaults to 7): Number of lags to create\n",
    "\n",
    "    Returns\n",
    "    ________\n",
    "        df (pd.DataFrame): Same input dataset but modified after adding the columns of lags\n",
    "    \"\"\"\n",
    "    # Creating lags\n",
    "    for i in range(1, lags + 1):\n",
    "        df[f\"y_lag_{i}\"] = df[column].shift(i).fillna(method='bfill')\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "General_Functions",
   "notebookOrigID": 154105517223476,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
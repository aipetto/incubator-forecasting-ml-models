{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "46a3a1bb-914d-4794-9e68-d9ed9109025f",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Notebook with the functions of the different forecasting models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ff7c57a2-23c1-48f0-89be-9f405062856a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This notebook contains the functions that allow to define and train forecasting models using the available algorithms,\n",
    "which are:\n",
    "\n",
    "  * SARIMAX\n",
    "  * Prophet\n",
    "  * LightGBM\n",
    "\n",
    "The functions included are:\n",
    "\n",
    "| Function | Description |\n",
    "| -------- | ----------- |\n",
    "| `obtain_sarimax`  | defines and trains a SARIMAX model using the given hyperparameters and input time series |\n",
    "| `obtain_prophet`  | defines and trains a Prophet model using the given hyperparameters and input time series |\n",
    "| `obtain_lightgbm`  | defines and trains a LightGBM model using the given hyperparameters and input time series |\n",
    "| `create_regressors_lightgbm`  | generate autoregressive lags and leads considering available data in the test period\n",
    "| `forecast_loop_lightgbm`  | generates forecasts for a LightGBM model during the test period using a loop to create lags and leads, considering available data\n",
    "| `refit_generate_forecast`  | re-fits a model using all the available data before the back-testing set. Then the forecast for the back-testing window is generated using this newly retrained model |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1cbd4a44-aa24-40c5-8cc1-6f84e3f0f421",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###### Definition of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "28f3413f-8885-4bf4-b8a8-b5e17fcc81f4",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def obtain_sarimax(df_train, params, holidays=False):\n",
    "    \"\"\"\n",
    "    Defines and trains a SARIMAX model according to the specified parameters and input time series.\n",
    "\n",
    "    If \"holidays\" is set to True then it is assumed that \"df_train\" includes a binary column which indicates the\n",
    "    observations that correspond to holidays, this column will be used as an external regressor.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "        df_train (pd.DataFrame): Dataset with training time series.\n",
    "        params (dict): Dictionary with seasonal and non-seasonal order parameters of the model.\n",
    "        holidays (bool, defaults to False): Flag to indicate whether the dataset contains the holidays regressor or not.\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "        model (ARIMAResultsWrapper): Object with the SARIMAX model defined by \"params\" and trained with the given time\n",
    "            series.\n",
    "    \"\"\"\n",
    "    # Validating holidays column\n",
    "    if holidays:\n",
    "        exog = df_train[\"holiday\"]\n",
    "    else:\n",
    "        exog = None\n",
    "\n",
    "    # Defining and training SARIMAX model\n",
    "    model = ARIMA(\n",
    "        df_train[\"y\"],\n",
    "        exog=exog,\n",
    "        order=(params[\"p\"], params[\"d\"], params[\"q\"]),\n",
    "        seasonal_order=(params[\"P\"], params[\"D\"], params[\"Q\"], params[\"s\"]),\n",
    "        enforce_invertibility=False,\n",
    "        enforce_stationarity=False\n",
    "    ).fit()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fc77acf8-3eb2-4f76-91b9-8dee8acbce9a",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def obtain_prophet(df_train, params, df_holidays=None):\n",
    "    \"\"\"\n",
    "    Defines and trains a Prophet model according to the specified parameters and input time series.\n",
    "\n",
    "    If \"df_holidays\" is different from \"None\" then it is assumed that this variable contains a DataFrame with the\n",
    "    holidays in the format Prophet expects them to be.\n",
    "\n",
    "    It is necessary to consider that Prophet requires the date column to be labeled as \"ds\" and the series column to be\n",
    "    labeled as \"y\". The same naming convention is required for the DataFrame with the holidays as well, with a column\n",
    "    named \"holiday\" which must contain the name of the holiday.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "        df_train (pd.DataFrame): Dataset with training time series.\n",
    "        params (dict): Dictionary with the hyperparameters of the model.\n",
    "        df_holidays (pd.DataFrame, defaults to None): Dataset with holidays.\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "        model (prophet.forecaster.Prophet): Object with the Prophet model defined by \"params\" and trained with the given\n",
    "            time series.\n",
    "    \"\"\"\n",
    "    # Defining and training Prophet model\n",
    "    model = Prophet(\n",
    "        changepoint_range=0.9,\n",
    "        daily_seasonality=False,\n",
    "        holidays=df_holidays,\n",
    "        changepoint_prior_scale=params[\"changepoint_prior_scale\"],\n",
    "        seasonality_prior_scale=params[\"seasonality_prior_scale\"],\n",
    "        holidays_prior_scale=params[\"holidays_prior_scale\"],\n",
    "    ).fit(df_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_lightgbm(df_train, params, holidays=False):\n",
    "    \"\"\"\n",
    "    Defines and trains a LightGBM model according to the specified parameters and input time series.\n",
    "\n",
    "    If \"holidays\" is set to True then it is assumed that \"df_train\" includes a binary column which indicates the\n",
    "    observations that correspond to holidays, this column will be used as an external regressor.\n",
    "\n",
    "    It is also assumed that the DataFrame has the following column structure: [\"ds\"] + regressor_columns + [\"y\"].\n",
    "        - \"ds\" being the date column\n",
    "        - \"y\" being the time series observations column\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "        df_train (pd.DataFrame): Dataset with training time series.\n",
    "        params (dict): Dictionary with the hyperparameters of the model.\n",
    "        holidays (bool, defaults to False): Flag to indicate whether the dataset contains the holidays regressor or not.\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "        model (lightgbm.sklearn.LGBMRegressor): Object with the LightGBM model defined by \"params\" and trained with the given time\n",
    "            series.\n",
    "    \"\"\"\n",
    "    # Validating holidays column\n",
    "    if not holidays:\n",
    "        try:\n",
    "            # Trying to drop the holidays column\n",
    "            df_train = df_train.drop(columns=[\"holidays\"])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Defining and training LightGBM model\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        reg_alpha=params[\"reg_alpha\"],\n",
    "        reg_lambda=params[\"reg_lambda\"]\n",
    "    ).fit(df_train.iloc[:, 1:-1], df_train.iloc[:, -1])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regressors_lightgbm(data_full, data_date, lags=7):\n",
    "    \"\"\"\n",
    "    Function that re-calculates auto regressive variables at every forecast iteration.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "        data_full (pd.DataFrame): Dataset with dates and values of the target value for the training set and the predicted\n",
    "            values of the test set\n",
    "        data_date (pd.DataFrame): Dataset with test time series for a particular date\n",
    "        lags (int, defaults to 7): Number of lags to create\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "    data_date (pd.DataFrame): Dataset with test time series for a particular date with the corrected autoregressors.\n",
    "    \"\"\"\n",
    "    # Save column order\n",
    "    col_order = list(data_date.columns)\n",
    "\n",
    "    # Concat data_full and data_date to calculate regressors\n",
    "    data_date_target = data_date[['ds', 'y']].copy()\n",
    "    data_date_target['y'] = np.nan\n",
    "    data_full_date = pd.concat([data_full, data_date_target], ignore_index=True)\n",
    "\n",
    "    # Create lags the target column\n",
    "    auto_regressors = []\n",
    "    for i in range(1, lags+1):\n",
    "        data_full_date[f\"y_lag_{i}\"] = data_full_date['y'].shift(i).fillna(method='bfill')\n",
    "        auto_regressors.append(f\"y_lag_{i}\")\n",
    "\n",
    "    # Drop existing lags and leads for data_date\n",
    "    data_date.drop(columns=auto_regressors, inplace=True)\n",
    "\n",
    "    # Merge new regressors\n",
    "    data_full_date = data_full_date[['ds'] + auto_regressors]\n",
    "    data_date = pd.merge(data_date, data_full_date, how='left', on=['ds'])\n",
    "    data_date = data_date[col_order]\n",
    "    return data_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_lightgbm(data_train, data_test, model):\n",
    "    \"\"\"\n",
    "    Makes a prediction in a loop fashion for every data point in the forecasting horizon. For the autoregressive variables,\n",
    "    we re-calculate them at every iteration, while the external regressors are kept as they are.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "        data_train (pd.DataFrame): Dataset with training time series.\n",
    "        data_test (pd.DataFrame): Dataset with test time series.\n",
    "        model (lightgbm.sklearn.LGBMRegressor): LightGBM model to use to generate predictions.\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "        pred (np.ndarray): Forecast of the test set\n",
    "    \"\"\"\n",
    "    # We create an auxiliary dataframe in which we'll include all the history of the target column and will populate it\n",
    "    # with forecasts\n",
    "    data_train = data_train.reset_index(drop=True)\n",
    "    data_test = data_test.reset_index(drop=True)\n",
    "    data_full = data_train[['ds', 'y']]\n",
    "\n",
    "    pred = []\n",
    "\n",
    "    # Do a forecast in a loop fashion\n",
    "    for j in range(len(data_test)):\n",
    "        date_i = data_test['ds'][j]\n",
    "        # Filter data for that particular date\n",
    "        data_date = data_test[data_test['ds'] == date_i]\n",
    "\n",
    "        # Create new regressors and predict\n",
    "        data_date = create_regressors_lightgbm(data_full.copy(), data_date)\n",
    "        pred_i = model.predict(data_date.iloc[:, 1:-1].values)[0]\n",
    "\n",
    "        # Append predictions\n",
    "        pred.append(pred_i)\n",
    "        \n",
    "        # Update data_full\n",
    "        pred_date = pd.DataFrame(data={\n",
    "            'ds': [date_i],\n",
    "            'y': [pred_i]\n",
    "        })\n",
    "        data_full = pd.concat([data_full, pred_date], ignore_index=True)\n",
    "\n",
    "\n",
    "    pred = np.array(pred)\n",
    "\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9adee447-b19d-4444-9fd8-1946298df2ce",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def refit_generate_forecast(algorithm, params, df_trainval, df_test, holidays=False, df_holidays=None):\n",
    "    \"\"\"\n",
    "    Re-fits a model using all the available data before the back-testing set. Then the forecast for the back-testing\n",
    "    window is generated using this newly retrained model.\n",
    "\n",
    "    Given that models built with native time series algorithms such as Prophet and SARIMAX can only be trained once, the\n",
    "    re-fitting happens by creating a new object using the already known hyperparameters and then training this object\n",
    "    with the new data.\n",
    "\n",
    "    Back-testing forecast generated with the re-trained object are compared against the actual values of the test set to\n",
    "    measure the final performance of the model.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "        algorithm (str): Algorithm used by the model to re-train.\n",
    "        params (dict): Dictionary with the hyperparameters of the model to re-train.\n",
    "        df_trainval (pd.DataFrame): Dataset with data to re-train the model.\n",
    "        df_test (pd.DataFrame): Back-testing dataset.\n",
    "        holidays (bool, defaults to False): Flag to indicate whether the holidays are included or not.\n",
    "        df_holidays (pd.DataFrame, defaults to None): Dataset with holidays.\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "        df_output (pd.DataFrame): Table with the forecast for the back-testing window.\n",
    "        test_wape (float): Back-test WAPE.\n",
    "    \"\"\"\n",
    "    # Validating if holidays are included\n",
    "    if holidays and (algorithm == \"sarimax\"):\n",
    "        exog = df_test[\"holiday\"].values\n",
    "    elif holidays and (algorithm == \"prophet\"):\n",
    "        df_hlds = df_holidays.copy()\n",
    "    else:\n",
    "        exog = None\n",
    "        df_hlds = None\n",
    "\n",
    "    # Validating the algorithm\n",
    "    if algorithm == \"sarimax\":\n",
    "        # Re-fitting the model\n",
    "        model = obtain_sarimax(df_trainval, params, holidays=holidays)\n",
    "\n",
    "        # Generating forecast for the back-test set\n",
    "        test_fcsts = model.predict(\n",
    "            start=len(df_trainval),\n",
    "            end=len(df_trainval) + len(df_test) - 1,\n",
    "            exog=exog,\n",
    "            typ=\"levels\"\n",
    "        )\n",
    "        fcst = test_fcsts.values\n",
    "\n",
    "        # Calculating performance metric\n",
    "        test_wape = wape(df_test[\"y\"].values, test_fcsts.values)\n",
    "        \n",
    "    if algorithm == \"lightgbm\":\n",
    "        # Re-fitting the model\n",
    "        model = obtain_lightgbm(df_trainval, params, holidays=holidays)\n",
    "\n",
    "        # Generating forecast for the back-test set\n",
    "        fcst = forecast_lightgbm(df_trainval, df_test, model)\n",
    "\n",
    "        # Calculating performance metric\n",
    "        test_wape = wape(df_test[\"y\"].values, fcst)        \n",
    "\n",
    "    elif algorithm == \"prophet\":\n",
    "        # Re-fitting the model\n",
    "        model = obtain_prophet(df_trainval, params, df_holidays=df_hlds)\n",
    "\n",
    "        # Generating forecast for the back-test set\n",
    "        test_fcsts = model.predict(df_test)[[\"ds\", \"yhat\"]]\n",
    "        fcst = test_fcsts[\"yhat\"].values\n",
    "\n",
    "        # Calculating performance metric\n",
    "        test_wape = wape(df_test[\"y\"].values, test_fcsts[\"yhat\"].values)\n",
    "\n",
    "    # Creating output table\n",
    "    df_output = pd.DataFrame({\"algorithm\": algorithm,\"ds\": df_test[\"ds\"].values, \"fcst\": fcst})\n",
    "\n",
    "    return df_output, test_wape\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Forecasting_Models",
   "notebookOrigID": 154105517223469,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
